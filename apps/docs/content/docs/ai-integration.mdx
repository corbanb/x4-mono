---
title: AI Integration
description: Using the AI generation endpoint with Claude
---

The x4 API includes an AI text generation endpoint powered by the Vercel AI SDK and Anthropic Claude.

## Generate Text

Send a prompt and receive AI-generated text:

```bash
curl -X POST http://localhost:3002/api/ai/generate \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Explain TypeScript generics in 3 sentences",
    "maxTokens": 500
  }'
```

Response:

```json
{
  "text": "TypeScript generics allow you to write...",
  "tokensUsed": 142,
  "estimatedCost": 0.00213
}
```

## Parameters

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `prompt` | string | Yes | — | The input prompt (1-10,000 chars) |
| `systemPrompt` | string | No | — | System instruction for the AI model |
| `maxTokens` | number | No | 1000 | Maximum output tokens (1-4,000) |

## Response Fields

| Field | Type | Description |
|-------|------|-------------|
| `text` | string | The generated text response |
| `tokensUsed` | number | Total tokens consumed (input + output) |
| `estimatedCost` | number | Estimated cost in USD |

## Token Limits

- **Max input prompt**: 10,000 characters
- **Max output tokens**: 4,000
- **Default output tokens**: 1,000

## Cost Tracking

Every AI request is logged to the `ai_usage_log` table with:
- User ID
- Model used
- Tokens consumed
- Estimated cost
- Endpoint called

This allows monitoring AI spend per user and per endpoint.

## Rate Limiting

The AI endpoint has a stricter rate limit of **10 requests per 60 seconds** per IP address, compared to the general limit of 100/60s.

## Using with tRPC

```typescript
const result = await trpc.ai.generate.mutate({
  prompt: "Write a haiku about TypeScript",
  systemPrompt: "You are a creative poet",
  maxTokens: 200,
});

console.log(result.text);
console.log(`Cost: $${result.estimatedCost.toFixed(4)}`);
```

## Error Handling

If the AI provider fails, the API returns a 500 error:

```json
{
  "code": "INTERNAL_SERVER_ERROR",
  "message": "AI generation failed"
}
```

Common causes:
- Invalid API key (`ANTHROPIC_API_KEY`)
- Rate limiting from the AI provider
- Prompt exceeding model context window
